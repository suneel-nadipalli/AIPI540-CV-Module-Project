{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "pb13uiD3MPFx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "import skimage\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "from sklearn import svm\n",
        "\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting input directory for bird and squirrel images\n",
        "\n",
        "input_dir = '/content/drive/MyDrive/CV_data'\n",
        "\n",
        "# listing possible image categories in folder\n",
        "categories = ['Bird', 'Squirrel']"
      ],
      "metadata": {
        "id": "D2w1vtVuMVkF"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def prepare_images(input_dir, category):\n",
        "\n",
        "'''\n",
        "This function takes in the input directory and the category of the images and returns the images and their labels as a list.\n",
        "The function also resizes the images to 224x224 pixels and converts the image to grayscale.\n",
        "\n",
        "Args:\n",
        "\n",
        "input_dir: str: The directory where the images are stored\n",
        "category: str: The category of the images/labels of the folders that contain the images\n",
        "\n",
        "Returns:\n",
        "\n",
        "data_array: list: A list containing flattened image information\n",
        "\n",
        "labels_array: list: A list of the labels of the images\n",
        "'''\n",
        "\n",
        "# creating empty lists to store data and labels\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "    # looping through Bird and Squirrel categories in the folder\n",
        "\n",
        "for category in categories:\n",
        "\n",
        "    # looping through the images in each category\n",
        "\n",
        "    for file in os.listdir(os.path.join(input_dir, category)):\n",
        "\n",
        "        # reading the image\n",
        "\n",
        "        image = imread(os.path.join(input_dir, category, file))\n",
        "\n",
        "        # resizing the image\n",
        "\n",
        "        image = resize(image, (224, 224, 3))\n",
        "\n",
        "        #converting the image to greyscale\n",
        "\n",
        "        image = skimage.color.rgb2gray(image)\n",
        "\n",
        "        # normalizing the pixel values\n",
        "\n",
        "        image = image / 255\n",
        "\n",
        "        # flattening the image\n",
        "\n",
        "        image = image.flatten()\n",
        "\n",
        "        # append the image data to the list data\n",
        "\n",
        "        data.append(image)\n",
        "\n",
        "        # append the label to the list labels\n",
        "\n",
        "        labels.append(category)\n",
        "\n",
        "# converting lists data and labels into numpy arrays\n",
        "data_array = np.array(data)\n",
        "labels_array = np.array(labels)\n",
        "\n",
        "# returning the completed arrays\n",
        "return data_array, labels_array"
      ],
      "metadata": {
        "id": "5yFuHcYlMfjG"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM Model Performance"
      ],
      "metadata": {
        "id": "1WSy_5fH4aR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_svm(data_array, labels_array):\n",
        "\n",
        "  '''\n",
        "  This function takes in the data and labels arrays and splits them into training and testing sets using sklearn's train_test_split\n",
        "  20 percent of the data is used for testing and 80 percent for training\n",
        "  The function then trains a support vector machine model using the training data and tests the model using the testing data\n",
        "  The function then prints the accuracy, confusion matrix and classification report of the model\n",
        "  The function returns the trained model\n",
        "\n",
        "  Args:\n",
        "\n",
        "  data_array: numpy array of the data\n",
        "  labels_array: numpy array of the labels\n",
        "\n",
        "  Returns: svm_model: trained support vector machine model\n",
        "  '''\n",
        "\n",
        "# using train test split to split data into training and test sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_array, labels_array, test_size=0.2, random_state=42)\n",
        "\n",
        "# initializing the SVM model\n",
        "\n",
        "svm_model = svm.SVC(kernel='linear', C=1, gamma=1)\n",
        "\n",
        "# training the SVM model\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# making predictions on the test set\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# printing accuracy, confusion matrix, and classification report\n",
        "\n",
        "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred), 2))\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# returning trained svm_model\n",
        "return svm_model"
      ],
      "metadata": {
        "id": "icHCRh_INCfG"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing data using the prepare_images function above\n",
        "\n",
        "data_array, labels_array = prepare_images(input_dir, categories)\n",
        "\n",
        "# training the SVC model and printing results\n",
        "svm_model = train_svm(data_array, labels_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MCl_n3iNOy7",
        "outputId": "654cb2f9-34f1-40a0-e8c7-7a2937ec75ae"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.61\n",
            "[[1017    1]\n",
            " [ 664   38]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Bird       0.60      1.00      0.75      1018\n",
            "    Squirrel       0.97      0.05      0.10       702\n",
            "\n",
            "    accuracy                           0.61      1720\n",
            "   macro avg       0.79      0.53      0.43      1720\n",
            "weighted avg       0.76      0.61      0.49      1720\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ouput Directory\n",
        "output_dir = '/content/Test_Images'\n",
        "\n",
        "\n",
        "# Saving Test Set Images for Use in Mean Model Comparison\n",
        "for i in range(0, len(X_test)):\n",
        "\n",
        "    plt.imshow(X_test[i].reshape(224,224), cmap='gray')\n",
        "    plt.savefig(os.path.join(output_dir, f'Test_{i}.png'))\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "FvLXbOM14t2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean Model Comparison\n"
      ],
      "metadata": {
        "id": "zY3j0LAN4XHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing required packages\n",
        "import torch\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "from torchvision.io import read_image, ImageReadMode"
      ],
      "metadata": {
        "id": "enTePIfygqFd"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def alex_net_model(X_test):\n",
        "\n",
        "  '''\n",
        "\n",
        "  This function calls a pretrained AlexNet model\n",
        "  It runs the test images we created above through the network and generates predictions\n",
        "  It then prints these classification predictions along with the probability percentage\n",
        "\n",
        "  Args:\n",
        "\n",
        "  X_test: numpy array of the test images\n",
        "\n",
        "  Returns: None\n",
        "\n",
        "  '''\n",
        "\n",
        "  # initializing pretrained alexnet model\n",
        "  model = models.alexnet(pretrained=True)\n",
        "  # putting model in evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # defining transforms that will be applied to the image\n",
        "\n",
        "  preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "    mean=[0.485, 0.456, 0.406],\n",
        "    std=[0.229, 0.224, 0.225]\n",
        "  )])\n",
        "\n",
        "  # initializing empty list for storing predictions\n",
        "  preds = []\n",
        "\n",
        "  # calling classes used in alexnet model for labelling\n",
        "  with open('/content/Doc4.txt') as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    # iterate through images in Test_Images folder, transforming images, conerting to tensor, then\n",
        "    # running through alexnet network and printing list of predictions along with image label\n",
        "\n",
        "  for i in range(0, len(X_test)):\n",
        "\n",
        "    test_image_path = f'/content/Test_Images/Test_{i}.png'\n",
        "\n",
        "    img = Image.open(test_image_path).convert('RGB')\n",
        "\n",
        "    img_resized = img.resize((256,256))\n",
        "\n",
        "    img_t = preprocess(img_resized)\n",
        "\n",
        "    batch_t = torch.unsqueeze(img_t, 0)\n",
        "\n",
        "    out = alexnet(batch_t)\n",
        "\n",
        "    _ , indices = torch.sort(out, descending = True)\n",
        "\n",
        "    percentage = torch.nn.functional.softmax(out, dim = 1)[0]*100\n",
        "\n",
        "    print([(f'Test_{i}.png', classes[idx], percentage[idx].item()) for idx in indices[0][:1]])\n"
      ],
      "metadata": {
        "id": "2p9-2BVYgtaN"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alex_net_model(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFQkTHl36MsI",
        "outputId": "14827a83-377d-4c5f-9384-f755d13cf063"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Test_0.png', \"163: 'bloodhound, sleuthhound',\", 17.798553466796875)]\n",
            "[('Test_1.png', \"24: 'great grey owl, great gray owl, Strix nebulosa',\", 11.786393165588379)]\n",
            "[('Test_2.png', \"456: 'bow',\", 8.806989669799805)]\n",
            "[('Test_3.png', \"702: 'parallel bars, bars',\", 8.67601203918457)]\n",
            "[('Test_4.png', \"19: 'chickadee',\", 19.416351318359375)]\n",
            "[('Test_5.png', \"749: 'quill, quill pen',\", 14.097225189208984)]\n",
            "[('Test_6.png', \"445: 'bikini, two-piece',\", 29.146108627319336)]\n",
            "[('Test_7.png', \"164: 'bluetick',\", 11.506406784057617)]\n",
            "[('Test_8.png', \"677: 'nail',\", 9.151708602905273)]\n",
            "[('Test_9.png', \"512: 'corkscrew, bottle screw',\", 10.034878730773926)]\n",
            "[('Test_10.png', \"445: 'bikini, two-piece',\", 12.821274757385254)]\n",
            "[('Test_11.png', \"285: 'Egyptian cat',\", 15.141386985778809)]\n",
            "[('Test_12.png', \"921: 'book jacket, dust cover, dust jacket, dust wrapper',\", 54.79890060424805)]\n",
            "[('Test_13.png', \"405: 'airship, dirigible',\", 10.203818321228027)]\n",
            "[('Test_14.png', \"82: 'ruffed grouse, partridge, Bonasa umbellus',\", 21.908077239990234)]\n",
            "[('Test_15.png', \"13: 'junco, snowbird',\", 6.258827209472656)]\n",
            "[('Test_16.png', \"289: 'snow leopard, ounce, Panthera uncia',\", 11.755742073059082)]\n",
            "[('Test_17.png', \"21: 'kite',\", 32.7681770324707)]\n",
            "[('Test_18.png', \"702: 'parallel bars, bars',\", 25.060382843017578)]\n",
            "[('Test_19.png', \"20: 'water ouzel, dipper',\", 19.627857208251953)]\n",
            "[('Test_20.png', \"921: 'book jacket, dust cover, dust jacket, dust wrapper',\", 5.773621559143066)]\n",
            "[('Test_21.png', \"178: 'Weimaraner',\", 24.5629940032959)]\n",
            "[('Test_22.png', \"677: 'nail',\", 34.419734954833984)]\n",
            "[('Test_23.png', \"357: 'mink',\", 12.62222671508789)]\n",
            "[('Test_24.png', \"18: 'magpie',\", 10.833064079284668)]\n",
            "[('Test_25.png', \"373: 'macaque',\", 27.91650390625)]\n",
            "[('Test_26.png', \"900: 'water tower',\", 29.809362411499023)]\n",
            "[('Test_27.png', \"921: 'book jacket, dust cover, dust jacket, dust wrapper',\", 14.37656021118164)]\n",
            "[('Test_28.png', \"18: 'magpie',\", 28.314224243164062)]\n",
            "[('Test_29.png', \"448: 'birdhouse',\", 14.380793571472168)]\n",
            "[('Test_30.png', \"499: 'cleaver, meat cleaver, chopper',\", 11.905308723449707)]\n",
            "[('Test_31.png', \"405: 'airship, dirigible',\", 25.460752487182617)]\n",
            "[('Test_32.png', \"514: 'cowboy boot',\", 6.219978332519531)]\n",
            "[('Test_33.png', \"287: 'lynx, catamount',\", 42.306461334228516)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy 24%"
      ],
      "metadata": {
        "id": "5OzNJcb27Hx7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}