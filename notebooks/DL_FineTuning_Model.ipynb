{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T03:24:51.606982Z","iopub.status.busy":"2024-02-11T03:24:51.606243Z","iopub.status.idle":"2024-02-11T03:24:57.981276Z","shell.execute_reply":"2024-02-11T03:24:57.980209Z","shell.execute_reply.started":"2024-02-11T03:24:51.606946Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torchvision\n","from torchvision import transforms, datasets\n","from torch.utils.data import DataLoader, Dataset\n","from PIL import Image\n","import os"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T03:24:57.983600Z","iopub.status.busy":"2024-02-11T03:24:57.983139Z","iopub.status.idle":"2024-02-11T03:24:57.996072Z","shell.execute_reply":"2024-02-11T03:24:57.994665Z","shell.execute_reply.started":"2024-02-11T03:24:57.983572Z"},"trusted":true},"outputs":[],"source":["import random\n","class CustomDataset(Dataset):\n","    def __init__(self, root_dir, transform=None, percent=100):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.classes = os.listdir(root_dir)\n","        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n","        self.images = self._load_images(percent)\n","\n","    def _load_images(self, percent):\n","        images = []\n","        for cls in self.classes:\n","            class_dir = os.path.join(self.root_dir, cls)\n","            class_images = [f for f in os.listdir(class_dir) if f.endswith('.jpg')]\n","            if percent < 100:\n","                num_images = int(len(class_images) * (percent / 100.0))\n","                class_images = random.sample(class_images, num_images)\n","            for img_name in class_images:\n","                img_path = os.path.join(class_dir, img_name)\n","                images.append((img_path, self.class_to_idx[cls]))\n","        return images\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img_path, label = self.images[idx]\n","        img = Image.open(img_path).convert('RGB')\n","        if self.transform:\n","            img = self.transform(img)\n","        return img, label"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T03:24:57.997825Z","iopub.status.busy":"2024-02-11T03:24:57.997506Z","iopub.status.idle":"2024-02-11T03:24:58.600769Z","shell.execute_reply":"2024-02-11T03:24:58.599948Z","shell.execute_reply.started":"2024-02-11T03:24:57.997798Z"},"trusted":true},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","dataset = CustomDataset(root_dir='/kaggle/input/birds-and-squirrels/CV_data_v2/CV_data', transform=transform, percent=100)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T03:24:58.603810Z","iopub.status.busy":"2024-02-11T03:24:58.603075Z","iopub.status.idle":"2024-02-11T03:24:58.628607Z","shell.execute_reply":"2024-02-11T03:24:58.627830Z","shell.execute_reply.started":"2024-02-11T03:24:58.603774Z"},"trusted":true},"outputs":[],"source":["train_size = int(0.8 * len(dataset))\n","test_size = len(dataset) - train_size\n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n","\n","# Define data loaders\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T03:24:58.629986Z","iopub.status.busy":"2024-02-11T03:24:58.629697Z","iopub.status.idle":"2024-02-11T03:24:58.636905Z","shell.execute_reply":"2024-02-11T03:24:58.635908Z","shell.execute_reply.started":"2024-02-11T03:24:58.629962Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(6878, 1720)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["train_size, test_size"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T03:24:58.638400Z","iopub.status.busy":"2024-02-11T03:24:58.638036Z","iopub.status.idle":"2024-02-11T03:24:58.645739Z","shell.execute_reply":"2024-02-11T03:24:58.644958Z","shell.execute_reply.started":"2024-02-11T03:24:58.638374Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T03:25:02.550481Z","iopub.status.busy":"2024-02-11T03:25:02.549678Z","iopub.status.idle":"2024-02-11T03:25:03.458133Z","shell.execute_reply":"2024-02-11T03:25:03.457146Z","shell.execute_reply.started":"2024-02-11T03:25:02.550450Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 140MB/s] \n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# model = CustomCNN(num_classes=len(dataset.classes)).to(device)\n","\n","model = torchvision.models.resnet18(pretrained=True)\n","model.fc = torch.nn.Linear(model.fc.in_features, len(dataset.classes))\n","model = model.to(device)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T03:25:04.469158Z","iopub.status.busy":"2024-02-11T03:25:04.468807Z","iopub.status.idle":"2024-02-11T03:25:04.475015Z","shell.execute_reply":"2024-02-11T03:25:04.474023Z","shell.execute_reply.started":"2024-02-11T03:25:04.469132Z"},"trusted":true},"outputs":[],"source":["criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T03:25:06.824609Z","iopub.status.busy":"2024-02-11T03:25:06.824212Z","iopub.status.idle":"2024-02-11T03:30:48.750769Z","shell.execute_reply":"2024-02-11T03:30:48.749739Z","shell.execute_reply.started":"2024-02-11T03:25:06.824577Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/10], Loss: 0.1183, Accuracy: 95.75%, Time: 1 minutes 17 seconds\n","Epoch [2/10], Loss: 0.0522, Accuracy: 98.17%, Time: 0 minutes 29 seconds\n","Epoch [3/10], Loss: 0.0395, Accuracy: 98.59%, Time: 0 minutes 29 seconds\n","Epoch [4/10], Loss: 0.0226, Accuracy: 99.19%, Time: 0 minutes 28 seconds\n","Epoch [5/10], Loss: 0.0322, Accuracy: 98.81%, Time: 0 minutes 29 seconds\n","Epoch [6/10], Loss: 0.0271, Accuracy: 99.20%, Time: 0 minutes 28 seconds\n","Epoch [7/10], Loss: 0.0147, Accuracy: 99.51%, Time: 0 minutes 29 seconds\n","Epoch [8/10], Loss: 0.0363, Accuracy: 98.82%, Time: 0 minutes 28 seconds\n","Epoch [9/10], Loss: 0.0061, Accuracy: 99.87%, Time: 0 minutes 30 seconds\n","Epoch [10/10], Loss: 0.0016, Accuracy: 99.99%, Time: 0 minutes 29 seconds\n"]}],"source":["import time\n","\n","# Train the model\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    start_time = time.time()  # Record start time of epoch\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item() * inputs.size(0)\n","        \n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    epoch_accuracy = correct / total * 100\n","    end_time = time.time()  # Record end time of epoch\n","    epoch_time = end_time - start_time\n","    minutes = int(epoch_time // 60)\n","    seconds = int(epoch_time % 60)\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%, Time: {minutes} minutes {seconds} seconds\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T03:30:54.067543Z","iopub.status.busy":"2024-02-11T03:30:54.067201Z","iopub.status.idle":"2024-02-11T03:31:13.702611Z","shell.execute_reply":"2024-02-11T03:31:13.701639Z","shell.execute_reply.started":"2024-02-11T03:30:54.067520Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy on test set: 99.71%\n"]}],"source":["model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f\"Accuracy on test set: {(correct / total) * 100:.2f}%\")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T03:31:31.537862Z","iopub.status.busy":"2024-02-11T03:31:31.537510Z","iopub.status.idle":"2024-02-11T03:31:31.546281Z","shell.execute_reply":"2024-02-11T03:31:31.545208Z","shell.execute_reply.started":"2024-02-11T03:31:31.537835Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torchvision import transforms\n","from PIL import Image\n","\n","# Load the image and apply transformations\n","\n","def predict_image(image_path, model):\n","\n","    image = Image.open(image_path).convert('RGB')\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                             std=[0.229, 0.224, 0.225])\n","    ])\n","    input_image = transform(image).unsqueeze(0)  # Add batch dimension\n","\n","    # Move input tensor to the device (GPU if available)\n","    input_image = input_image.to(device)\n","\n","    # Perform inference\n","    model.eval()\n","    with torch.no_grad():\n","        output = model(input_image)\n","\n","    # Get predicted class probabilities and class index\n","    probabilities = torch.softmax(output, dim=1)[0]\n","    predicted_class_index = torch.argmax(probabilities).item()\n","\n","    # Map class index to class label\n","    class_labels = dataset.classes\n","    predicted_class_label = class_labels[predicted_class_index]\n","\n","    return predicted_class_label, probabilities[predicted_class_index].item()\n","#     print(\"Class probabilities:\")\n","#     for i, prob in enumerate(probabilities):\n","#         print(f\"{class_labels[i]}: {prob:.4f}\")\n"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T04:16:13.190868Z","iopub.status.busy":"2024-02-11T04:16:13.190376Z","iopub.status.idle":"2024-02-11T04:16:13.197821Z","shell.execute_reply":"2024-02-11T04:16:13.196590Z","shell.execute_reply.started":"2024-02-11T04:16:13.190833Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['Bird', 'Squirrel']"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["dataset.classes"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T03:32:19.461019Z","iopub.status.busy":"2024-02-11T03:32:19.460154Z","iopub.status.idle":"2024-02-11T03:32:20.066511Z","shell.execute_reply":"2024-02-11T03:32:20.065553Z","shell.execute_reply.started":"2024-02-11T03:32:19.460981Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Actual Class: bird | Predicted Class: Bird\n","Actual Class: squirrel | Predicted Class: Squirrel\n","Actual Class: bird | Predicted Class: Bird\n","Actual Class: squirrel | Predicted Class: Squirrel\n","Actual Class: bird | Predicted Class: Bird\n","Actual Class: squirrel | Predicted Class: Squirrel\n","Actual Class: bird | Predicted Class: Bird\n","Actual Class: squirrel | Predicted Class: Squirrel\n","Actual Class: bird | Predicted Class: Bird\n","Actual Class: bird | Predicted Class: Bird\n","Actual Class: squirrel | Predicted Class: Squirrel\n","Actual Class: squirrel | Predicted Class: Bird\n","Actual Class: squirrel | Predicted Class: Squirrel\n","Actual Class: bird | Predicted Class: Bird\n","Actual Class: squirrel | Predicted Class: Squirrel\n","Actual Class: squirrel | Predicted Class: Squirrel\n","Actual Class: squirrel | Predicted Class: Bird\n","Actual Class: bird | Predicted Class: Bird\n","Actual Class: bird | Predicted Class: Bird\n","Actual Class: bird | Predicted Class: Squirrel\n"]}],"source":["import glob\n","\n","for test_img in glob.glob(\"/kaggle/input/aipi540-test/test/*\"):\n","    actual_class = test_img.split(\"/\")[-1].split(\"_\")[0]\n","    \n","    pred_class = predict_image(test_img, model)\n","    \n","    print(f\"Actual Class: {actual_class} | Predicted Class: {pred_class}\")"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-02-10T22:23:12.095192Z","iopub.status.busy":"2024-02-10T22:23:12.094503Z","iopub.status.idle":"2024-02-10T22:23:12.173331Z","shell.execute_reply":"2024-02-10T22:23:12.172310Z","shell.execute_reply.started":"2024-02-10T22:23:12.095162Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model saved to resnet18_custom_model.pth\n"]}],"source":["# Define the file path to save the model\n","model_path = 'resnet18_custom_model.pth'\n","\n","# Save the model\n","torch.save(model.state_dict(), model_path)\n","\n","print(f\"Model saved to {model_path}\")"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T03:32:54.687354Z","iopub.status.busy":"2024-02-11T03:32:54.686960Z","iopub.status.idle":"2024-02-11T03:32:54.785715Z","shell.execute_reply":"2024-02-11T03:32:54.784744Z","shell.execute_reply.started":"2024-02-11T03:32:54.687324Z"},"trusted":true},"outputs":[],"source":["import pickle\n","\n","model_path = 'model.pkl'\n","with open(model_path, 'wb') as f:\n","    pickle.dump(model, f)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-02-10T22:24:49.357436Z","iopub.status.busy":"2024-02-10T22:24:49.356571Z","iopub.status.idle":"2024-02-10T22:24:49.653807Z","shell.execute_reply":"2024-02-10T22:24:49.652829Z","shell.execute_reply.started":"2024-02-10T22:24:49.357396Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=2, bias=True)\n",")"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["model_loaded = torchvision.models.resnet18(pretrained=False)  # Initialize ResNet18 without pretraining\n","model_loaded.fc = torch.nn.Linear(model_loaded.fc.in_features, len(dataset.classes))  # Modify the fully connected layer\n","model_loaded = model_loaded.to(device)  # Move the model to the appropriate device (GPU or CPU)\n","\n","# Load the saved state dictionary into the model\n","model_path = '/kaggle/working/resnet18_custom_model.pth'\n","model_loaded.load_state_dict(torch.load(model_path))\n","\n","# Set the model to evaluation mode\n","model_loaded.eval()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T03:33:11.481265Z","iopub.status.busy":"2024-02-11T03:33:11.480287Z","iopub.status.idle":"2024-02-11T03:33:11.567339Z","shell.execute_reply":"2024-02-11T03:33:11.566299Z","shell.execute_reply.started":"2024-02-11T03:33:11.481213Z"},"trusted":true},"outputs":[],"source":["with open(model_path, 'rb') as f:\n","    loaded_model = pickle.load(f)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T03:33:16.747934Z","iopub.status.busy":"2024-02-11T03:33:16.746599Z","iopub.status.idle":"2024-02-11T03:33:17.204944Z","shell.execute_reply":"2024-02-11T03:33:17.203119Z","shell.execute_reply.started":"2024-02-11T03:33:16.747893Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Actual Class: bird | Predicted Class: Bird\n","Actual Class: squirrel | Predicted Class: Squirrel\n","Actual Class: bird | Predicted Class: Bird\n","Actual Class: squirrel | Predicted Class: Squirrel\n","Actual Class: bird | Predicted Class: Bird\n","Actual Class: squirrel | Predicted Class: Squirrel\n","Actual Class: bird | Predicted Class: Bird\n","Actual Class: squirrel | Predicted Class: Squirrel\n","Actual Class: bird | Predicted Class: Bird\n","Actual Class: bird | Predicted Class: Bird\n","Actual Class: squirrel | Predicted Class: Squirrel\n","Actual Class: squirrel | Predicted Class: Bird\n","Actual Class: squirrel | Predicted Class: Squirrel\n","Actual Class: bird | Predicted Class: Bird\n","Actual Class: squirrel | Predicted Class: Squirrel\n","Actual Class: squirrel | Predicted Class: Squirrel\n","Actual Class: squirrel | Predicted Class: Bird\n","Actual Class: bird | Predicted Class: Bird\n","Actual Class: bird | Predicted Class: Bird\n","Actual Class: bird | Predicted Class: Squirrel\n"]}],"source":["import glob\n","\n","for test_img in glob.glob(\"/kaggle/input/aipi540-test/test/*\"):\n","    actual_class = test_img.split(\"/\")[-1].split(\"_\")[0]\n","    \n","    pred_class = predict_image(test_img, loaded_model)\n","    \n","    print(f\"Actual Class: {actual_class} | Predicted Class: {pred_class}\")"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T00:25:55.219849Z","iopub.status.busy":"2024-02-11T00:25:55.218915Z","iopub.status.idle":"2024-02-11T00:25:56.171566Z","shell.execute_reply":"2024-02-11T00:25:56.170620Z","shell.execute_reply.started":"2024-02-11T00:25:55.219817Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Actual Class: /kaggle/input/test-2/small_bird_2_day.jpg | Predicted Class: Bird\n","Actual Class: /kaggle/input/test-2/squirrel_2.jpg | Predicted Class: Squirrel\n","Actual Class: /kaggle/input/test-2/night_bird_1.jpg | Predicted Class: Bird\n","Actual Class: /kaggle/input/test-2/parrot_3_day.jpg | Predicted Class: Bird\n","Actual Class: /kaggle/input/test-2/night_bird_3.jpg | Predicted Class: Bird\n","Actual Class: /kaggle/input/test-2/squirrel_4_day.jpg | Predicted Class: Squirrel\n","Actual Class: /kaggle/input/test-2/bird_group_1_day.jpg | Predicted Class: Squirrel\n","Actual Class: /kaggle/input/test-2/night_bird_2.jpg | Predicted Class: Bird\n","Actual Class: /kaggle/input/test-2/squirrel_1_dayjpg.jpg | Predicted Class: Squirrel\n","Actual Class: /kaggle/input/test-2/squirrel_1.jpg | Predicted Class: Squirrel\n","Actual Class: /kaggle/input/test-2/squirrel_5.jpg | Predicted Class: Squirrel\n","Actual Class: /kaggle/input/test-2/parrot_2.jpg | Predicted Class: Squirrel\n","Actual Class: /kaggle/input/test-2/parrot_2_day.jpg | Predicted Class: Bird\n","Actual Class: /kaggle/input/test-2/parrot_1_day.jpg | Predicted Class: Bird\n","Actual Class: /kaggle/input/test-2/squirrel_2_day.jpg | Predicted Class: Squirrel\n","Actual Class: /kaggle/input/test-2/parrot_1.jpg | Predicted Class: Bird\n","Actual Class: /kaggle/input/test-2/squirrel_3_day.jpg | Predicted Class: Squirrel\n"]}],"source":["import glob\n","\n","for test_img in glob.glob(\"/kaggle/input/test-2/*\"):\n","#     actual_class = test_img.split(\"/\")[-1].split(\"_\")[0]\n","    \n","    pred_class = predict_image(test_img, model_loaded)\n","    \n","    print(f\"Actual Class: {test_img} | Predicted Class: {pred_class}\")"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T03:56:42.496811Z","iopub.status.busy":"2024-02-11T03:56:42.496449Z","iopub.status.idle":"2024-02-11T03:56:42.502722Z","shell.execute_reply":"2024-02-11T03:56:42.501687Z","shell.execute_reply.started":"2024-02-11T03:56:42.496785Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'0.16.2'"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["torchvision.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4387161,"sourceId":7541936,"sourceType":"datasetVersion"},{"datasetId":4397055,"sourceId":7549818,"sourceType":"datasetVersion"},{"datasetId":4400422,"sourceId":7555835,"sourceType":"datasetVersion"},{"datasetId":4426340,"sourceId":7603255,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
